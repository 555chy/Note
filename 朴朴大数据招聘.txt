
大数据开发岗位职责：
1、参加大数据流批处理的研发，如实时计算通用组件研发、元数据、血缘分析、指标管理平台、质量管理平台等；
2、支持业务数据报告需求；
3、大数据资源的调度和优化；
4、协助运维做好集群的维护工作；
5、积极主动研究大数据时代的各种前沿技术、并能在产品中得以运用实施。
任职要求：
1、2年以上大数据开发经验，精通数据结构和算法，优秀的故障排查和架构设计能力；
2、有从事分布式数据存储与计算平台应用开发经验，熟悉 hadoop/spark，有海量数据处理能力；
3、熟练掌握 kafka，有实时流计算项目经验（storm/spark-streaming/flink，熟练掌握其中一种流式计算框架）；
4、掌握 Linux 系统下编程经验，熟练掌握一门脚本予言（shell，python 等）；
5、熟悉 MPP 数据库的建模、使用和性能调优（如 HBase，ElasticSearch）；
6、注重代码规范，具有良好的学习能力、文档能力、沟通能力、团队合作意识；
7、强烈的责任心与主动性，对所负责工作有主人翁意识，并能自我驱动成长。
加分项：
- 具有大数据运维经验
- 对 kafka/spark 等大数据项目的源码有研究
- 熟悉 Pulsar 等开源的消息队列系统
- 对 ClickHouse 有研究
- 掌握 Kimball/data vault 的维度建模设计方法优先考虑

大数据运维工作职责：
1、负责公司数据平台的部署、管理、优化、监控报警，保障平台服务稳定可靠，推动数据平台运维自动化；
2、参与公司数据平台架构设计，发现并解决性能瓶颈，支撑业务和数据量的快速增长，持续优化。
任职要求：
1、本科及以上学历，2年以上互联网公司大数据运维经验；
2、理解Linux系统,熟练配置网络环境,精通一门以上脚本语言,熟悉运维体系结构；
3、掌握Hadoop, Kafka, Zookeeper, Hbase, Spark等常用大数据框架和组件的原理、部署及监控与故障处理;有能力承担一整套大数据平台的软件架构选型；
4、了解数据挖掘，机器学习等领域相关知识；
5、具有良好的学习能力、文档能力、沟通能力、团队协作意识。

职位亮点：
千万用户，百万日活，亿级请求，高值期权
即时配送电商明星玩家，新零售独角兽 
