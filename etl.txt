datax与kettel性能对比
https://blog.csdn.net/lanxuxml/article/details/103600706
https://blog.csdn.net/weixin_44411398/article/details/116695232
            DataX       Kettle
10万数据       10s         27s
100万数据      80s         306s

两者差别：
1.Kettle基本不需要编写代码，图形界面配置；DataX需要编写配置文件，命令行执行
2.Kettel不支持clickhouse和hana；DataX支持写clickhouse，hana可以用rdbms插件进行读写

ETL与ELT
1.ETL架构
ETL架构按其字面含义理解就是按照E-T-L这个顺序流程进行处理的架构：先抽取、然后转换、完成后加载到目标数据库中。在ETL架构中，数据的流向是从源数据流到ETL工具，ETL工具是一个单独的数据处理引擎，一般会在单独的硬件服务器上，实现所有数据转化的工作，然后将数据加载到目标数据仓库中。如果要增加整个ETL过程的效率，则只能增强ETL工具服务器的配置，优化系统处理流程（一般可调的东西非常少）
优势:
（1）可以分担数据库系统的负载（采用单独的硬件服务器）
（2）相对于ELT架构可以实现更为复杂的数据转换逻辑
（3）采用单独的硬件服务器
（4）与底层的数据库存储无关

2.ELT架构
ELT架构则把“L”这一步工作提前到“T”之前来完成：先抽取、然后加载到目标数据库中、在目标数据库中完成转换操作。在ELT架构中，ELT只负责提供图形化的界面来设计业务规则，数据的整个加工过程都在目标和源的数据库之间流动，ELT协调相关的数据库系统来执行相关的应用，数据加工过程既可以在源数据库端执行，也可以在目标数据仓库端执行（主要取决于系统的架构设计和数据属性）。当ETL过程需要提高效率，则可以通过对相关数据库进行调优，或者改变执行加工的服务器就可以达到
优势:
（1）充分利用数据库引擎来实现的可扩展性
（2）可以保持所有的数据始终在数据库当中，避免数据的加载和导出，从而保证效率，提高系统的可监控性
（3）可以根据数据的分布情况进行并行处理优化，并可以利用数据库的固有功能优化磁盘I/O
（4）通过对相关数据库进行性能调优，ELT过程获得3到4倍的效率提升比较容易


ETL（数据同步）的5种方案
1.触发器：在数据库建立增删改的触发器。触发器将变更放到一张临时表里（oracle同步cdc）
优点：实时同步
缺点：影响到业务系统，因为需要在业务系统建立触发器
2.日志：通过分析数据库日志，来获得源数据库中变化的数据（oracle异步cdc）
优点：不影响业务系统
缺点：有一定的延时，对于没有提供日志分析接口的数据源，开发难度较大
3.时间戳：在要同步的源表里要有时间戳字段，每当数据发生变化，时间戳会记录发生变化的时间
优点：基本不影响业务系统
缺点：要求源表必须有时间戳这一列
4.数据比较：通过比较两边数据源的数据，来完成数据同步。一般用于实时性要求不高的场景
优点：基本不影响业务系统
缺点：效率低
5.全量同步：时清空目标数据源，将源数据的数据全盘拷贝到目标数据源。
优点：基本不影响业务系统
缺点：效率低。一般用于数据量不大，实时性要求不高的场景

总结：
1.上述5种数据同步方案，除了第五种，其它都需要业务表有主键
2.对于没有触发器和日志的一些小型数据源，如txt，excel，access，只能用后3种
3.对于大型数据源，一般优先选择日志方式，如Oracle Asynchronized CDC，对于不能通过日志来实现的情况，可以考虑1，3，4方案

一、DataX
为了解决异构数据源同步问题，DataX将复杂的网状的同步链路变成了星型数据链路，DataX作为中间传输载体负责连接各种数据源。当需要接入一个新的数据源的时候，只需要将此数据源对接到DataX，便能跟已有的数据源做到无缝数据同步。

DataX本身作为离线数据同步框架，采用Framework + plugin架构构建。将数据源读取和写入抽象成为Reader/Writer插件，纳入到整个同步框架中。

Reader：Reader为数据采集模块，负责采集数据源的数据，将数据发送给Framework。
Writer： Writer为数据写入模块，负责不断从Framework取数据，并将数据写入到目的端。
Framework：Framework用于连接reader和writer，作为两者的数据传输通道，并处理缓冲，流控，并发，数据转换等核心技术问题。

DataX完成单个数据同步的作业，我们称之为Job，DataX接受到一个Job之后，将启动一个进程来完成整个作业同步过程。DataX Job模块是单个作业的中枢管理节点，承担了数据清理、子任务切分(将单一作业计算转化为多个子Task)、TaskGroup管理等功能。
DataXJob启动后，会根据不同的源端切分策略，将Job切分成多个小的Task(子任务)，以便于并发执行。Task便是DataX作业的最小单元，每一个Task都会负责一部分数据的同步工作。
切分多个Task之后，DataX Job会调用Scheduler模块，根据配置的并发数据量，将拆分成的Task重新组合，组装成TaskGroup(任务组)。每一个TaskGroup负责以一定的并发运行完毕分配好的所有Task，默认单个任务组的并发数量为5。
每一个Task都由TaskGroup负责启动，Task启动后，会固定启动Reader—>Channel—>Writer的线程来完成任务同步工作。
DataX作业运行起来之后， Job监控并等待多个TaskGroup模块任务完成，等待所有TaskGroup任务完成后Job成功退出。否则，异常退出，进程退出值非0

DataX调度流程：举例来说，用户提交了一个DataX作业，并且配置了20个并发，目的是将一个100张分表的mysql数据同步到odps里面。 
DataX的调度决策思路是：
DataXJob根据分库分表切分成了100个Task。
根据20个并发，DataX计算共需要分配4个TaskGroup（20/5）。
4个TaskGroup平分切分好的100个Task，每一个TaskGroup负责以5个并发共计运行25个Task。

调优：
1.全局配置（DataX-master/target/datax/datax/conf/core.json）
{
   "entry": {
        "jvm": "-Xms3G -Xmx3G",
        "environment": {}
   },
   "core":{
        "transport":{
            "channel":{
                "speed":{
                    "channel": 2, ## 此处为数据导入的并发度，建议根据服务器硬件进行调优
                    "record":-1, ##此处解除对读取行数的限制
                    "byte":-1, ##此处解除对字节的限制
                    "batchSize":2048 ##每次读取batch的大小
                }
            }
        }
    }
}
2.jvm调优：python datax.py --jvm="-Xms3G -Xmx3G" ../job/test.json

实践: 编译、mysql导入到clickhouse
https://blog.csdn.net/chy555chy/article/details/118675428
https://blog.csdn.net/chy555chy/article/details/118700918
心得：
1.同步需要在目标数据库预先建立表结构
2.可以仅同步部分列
3.如果要实现增量同步——源表只增不改，需要额外createTime字段；源表不仅增还会改，需要createTime和updateTime字段

使用Linux中的crontab命令来定时执行脚本，脚本文件通过动态修改where语句的时间戳字段，来过滤源表中新增的项
https://www.lhtry.net/Blog/Detail/29

增量更新
https://blog.csdn.net/quadimodo/article/details/82186788
1.在 where 使用了sql 语句 create_time > FROM_UNIXTIME(${create_time}) and create_time < FROM_UNIXTIME(${end_time}) ，
其中FROM_UNIXTIME()是mysql时间戳转换为时间格式的函数，${name}是datax提供的占位符后面会使用到
2.reader中连接字符串添加了useUnicode=true&characterEncoding=utf8 ，因为没有加这个导入到目标数据库中文乱码了，虽然我两边的数据库都是utf8mb4格式的

二、kettle（Pentaho Data Integration）

Kettle最早是一个开源的ETL工具。
2006年，Pentaho 公司收购了Kettle，Kettle成为Pentaho的主要组成部分。
2015年，Hitachi Vantara收购了Pentaho，Kettle正式命名为PDI。

下载地址
https://community.hitachivantara.com/s/article/data-integration-kettle

文档
https://help.pentaho.com/Documentation/8.2/Products/Data_Integration



ETL（Extract-Transform-Load的缩写，即数据抽取、转换、装载的过程），例如，各种数据的处理，转换，迁移（数据抽取、质量检测、数据清洗、数据转换、数据过滤等）


一.离线ETL（异构数据源同步）
1.DataX 致力于实现包括关系型数据库(MySQL、Oracle等)、HDFS、Hive、ODPS、HBase、FTP等各种异构数据源之间稳定高效的数据同步功能.通过reader插件采集数据源数据，将数据发送给Framework,再通过Writer插件向Framework取数，并将数据写到目的端
（优点：可以通过自定义的读写插件，按需实现任意自定义规则的数据转换）
2.kettle 是一个非常强大的 ETL 工具，通过图形化界面的配置，可以实现数据迁移，并不用开发代码。通过它的作业，能自动转换异构数据源。
（优点：拥有图形配置界面）

二.实时ETL（Kafka+Flink+Clickhouse）
消息队列
1.Kafka 被誉为消息传递系统之王，全面具备：高吞吐量、低延迟、容错、持久性、可伸缩性等特质。大数据领域 Kafka 几乎无可替代，而业务领域众多 MQ 又各有所长。新一代云原生消息平台、Apache Pulsar 都可以满足
2.在实时流式架构中，消息用例可被分为两类：队列和流。而 Pulsar 最优秀的地方正在于此，它将队列和流合二为一，统一为消息传递模型（producer-topic-subscription-consumer）
也就是说，Pulsar 不仅可以如同 Kafka 一样处理高速率实时场景，还能支持传统的标准消息队列模式，例如多消费者和失效备援订阅等。
一个 Pulsar 系统，直接让你拥有 RabbitMQ + RocketMQ + Kafka 的各项特性。更惊艳的是，Pulsar 采用云原生架构，它的架构设计能够充分利用分布式且能弹性扩容云端资源，永久性告别性能不足，是未来的大趋势。

流批处理
1.Spark基于微批量处理，把流数据看成是一个个小的批处理数据块分别处理，所以延迟性只能做到秒级
（优点：Spark对SQL支持更好，相应的优化、扩展和性能更好，而Flink在SQL支持方面还有很大提升空间）
2.Flink基于每个事件处理，每当有新的数据输入都会立刻处理，是真正的流式计算，支持毫秒级计算
（优点：真正支持流计算，延迟低）

三、ELK（日志搜集、管理、查询的整套解决方案）
1.Elasticsearch是个开源分布式搜索引擎，提供搜集、分析、存储数据三大功能。它的特点有：分布式，零配置，自动发现，索引自动分片，索引副本机制，restful风格接口，多数据源，自动搜索负载等。
2.Logstash 主要是用来日志的搜集、分析、过滤日志的工具，支持大量的数据获取方式。一般工作方式为c/s架构，client端安装在需要收集日志的主机上，server端负责将收到的各节点日志进行过滤、修改等操作在一并发往elasticsearch上去。
3.Kibana 也是一个开源和免费的工具，Kibana可以为 Logstash 和 ElasticSearch 提供的日志分析友好的 Web 界面，可以帮助汇总、分析和搜索重要数据日志。


四、负载均衡
Nginx是著名的反向代理服务器，也被广泛的作为负载均衡服务器。每次负载，都充当一次中间人转发角色，增加网络负载量。存在单节点问题，当数据量大的时候nginx负载会很高。优点是自带负载均衡算法，不用自己去写。
ZooKeeper是分布式协调服务框架，有时也被用来做负载均衡。不存在单点问题，zab机制保证单点故障可重新选举一个leader不存在单点问题，zab机制保证单点故障可重新选举一个leader。只负责服务的注册与发现，不负责转发，减少一次数据交换（消费方与服务方直接通信），但需要自己实现相应的负载均衡算法


