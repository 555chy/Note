1.为什么使用redis
使用redis主要是从"性能"和"并发"去考虑。虽然redis还具备可以做分布式锁等其他功能，但如果只是为了分布式锁这些功能，完全还有其他中间件（如zookeeper等）代替
（1）性能：如果我们在碰到需要执行耗时特别久，且结果不频繁动的SQL，就特别适合将运行结果放入缓存，这样后面的请求就去缓存中读取，使得请求能够迅速响应
（2）并发：在大并发的情况下，所有的请求直接访问数据库，数据库会出现连接异常。这时候就需要redis做一个缓冲操作，让请求先访问redis，而不是直接访问数据库

2.使用redis有什么缺点
（1）缓存和数据库双写一致性问题
（2）缓存雪崩问题
（3）缓存击穿问题
（4）缓存的并发竞争问题

3.单线程的redis为什么这么快
（1）纯内存操作
（2）单线程操作，避免了频繁的上下文切换
（3）采用了非阻塞I/O多路复用机制（单个线程，通过跟踪每个I/O流的状态，来管理多个I/O流）
redis-client在操作的时候，会产生具有不同事件类型的socket。在服务端，有一段I/0多路复用程序，将其置入队列之中。然后，文件事件分派器，依次去队列中取，转发到不同的事件处理器中
redis还提供了select、epoll、evport、kqueue等多路复用函数库

4.redis的数据类型，以及每种数据类型的使用场景
（1）String：最常规的get/set操作，value可以是String也可以是数字。一般用作一些复杂的计数功能的缓存
（2）hash：这里的value存放的是结构化的对象，可以很方便的操作其中某个字段。做单点登录时，就是用这种数据结构存储用户信息，以cookieId作为key，设置30分钟为缓存过期时间，可以很好的模拟出类似session的效果
（3）list：使用list的结构，可以做简单的先进先出的消息队列的功能。利用lrange命令，可以做基于redis的分页功能，性能极佳。
（4）set：用来存放一堆不重复值的集合，用作全局去重功能。之所以不能用JVM自带的Set去重，是因为我们的系统一般都是集群部署的。另外还可以利用交集、并集、差集等操作，计算共同喜好，全部喜好，自己独有的喜好等     
（5）sorted set：多了一个权重参数score，集合中的元素能够按照score进行排序。可以做排行榜应用，取TOP N操作

5.redis的过期策略以及内存淘汰机制
之所以没有采用定时删除策略，是因为定时删除用一个定时器来负责监视key，过期则自动删除。虽然内存及时释放，但是十分消耗CPU资源。在大并发请求下，CPU要将时间应用在处理请求，而不是删除key。所以没有采用这一策略。
redis采用的是定期删除+惰性删除策略。
定期删除，redis默认每隔100ms检查，是否有过期的key，有过期key则删除。需要说明的是redis不是每隔100ms将所有的key检查一次，而是随机抽取进行检查（如果每隔100ms，全部key进行检查，redis岂不是卡死）因此，如果只采用定期删除策略，会导致很多key到时间没有删除
于是惰性删除派上用场。也就是说你在获取某个key的时候，redis会检查一下，这个key是否设置了过期时间，如果过期了此时就会自动删除。
但这样会有一个问题，如果定期删除没删除key，你也没即时去请求可以。redis的内存会越来越高。那么就应该采用内存淘汰机制。在redis.conf中有一行配置 maxmemory-policy volatile-lru（LRU是Least Recently Used的缩写，即最近最少使用）
（1）noevicition：当内存不足以容纳新写入数据时，新写入操作会报错
（2）allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key（推荐）
（3）allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个key 
（4）volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key。这种情况一般是把redis既当缓存，又做持久化存储的时候才用
（5）volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key
（6）volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的key优先移除
如果没有设置expire的key，不满足先决条件（prerequisites）那么volatile-lru, volatile-random, volatile-ttl策略的行为和noevicition（不删除）基本上一致
     
6.redis的数据库双写一致性问题
一致性问题是分布式常见问题，可以再分为最终一致性和强一致性。数据库和缓存双写，就必然会存在不一致的问题。如果对数据有强一致性要求，则不能放缓存，另外，我们所做的方案其实从根本上来说，只能降低不一致发生的概率，无法完全避免。
首先，采取正确的更新策略，先更新数据库，再删缓存。其次，因为可能存在删除缓存失败的问题，提供一个补偿措施即可，例如利用消息队列

7.如何应对缓存穿透和缓存雪崩问题（大并发项目，流量有几百万，一定要深思熟虑）
（1）缓存穿透：即黑客故意去请求缓存中不存在的数据，导致所有的请求都怼到数据库上，因此数据库连接异常
解决方案：
 a）利用互斥锁，缓存失效的时候，先去获得锁，得到锁了，再去请求数据库。没有得到锁，则休眠一段时间后重试
 b）采用异步更新策略，无论key是否取到值，都直接返回。value值中维护一个缓存失效时间，缓存如果过期，异步起一个线程去读数据库，更新缓存。需要做缓存预热（项目启动前，先加载缓存）操作
 c）提供一个能迅速判断请求是否有效的拦截机制。比如，利用布隆过滤器，内部维护一系列合法有效的key。迅速判断出，请求所携带的Key是否合法有效，如果不合法，则直接返回
（2）缓存雪崩：即缓存同一时间大面积失效了，这时候又来了一波请求，结果请求都怼到数据库上，导致数据库连接异常
解决方案：
 a）给缓存的失效时间，加上一个随机值，避免集体失效
 b）使用互斥锁，但该方案会导致吞吐量明显下降
 c）双缓存。我们有两个缓存A和B。缓存A的失效时间为20分钟，缓存B不设失效时间。自己做缓存预热操作
  - 从缓存A读数据库，有则直接返回
  - A没有数据，直接从B读数据，直接返回，并且异步启动一个更新线程
  - 更新线程同时更新缓存A和缓存B

8.如何解决redis的并发竞争问题
同时有多个子系统去set一个key。不推荐使用redis的事务机制。因为生产环境，基本都是和集群，做了分片操作。你的一个事务中涉及到多个key操作的时候，这多个key不一定都存储在同一个redis-server上。因此，redis的事务机制，十分鸡肋
（1）如果对这个key操作，不要求顺序：准备一个分布式锁，大家去抢锁，抢到锁就做set操作
（2）如果对这个key操作，要求顺序：我们在数据写入数据库的时候，需要额外保存一个时间戳。例如
	系统A key1 {valueA 3:00}
	系统B key1 {valueB 3:05}
	系统C key1 {valueC 3:10}
	那么假设这会系统B先抢到锁，将key1设置为{valueB 3:05}。接下来系统A抢到锁，发现自己的valueA的时间戳早于缓存中的时间戳，那就不做set操作了。
	其他方法，比如利用队列，将set变成串行访问也可以



redis 语法（简明扼要）
https://www.cnblogs.com/jasonjson/p/12402763.html

数据文件每隔60s刷新到磁盘上，默认情况下，因此journal只需要持有60s内的写入数据
MongoDB每隔100ms写入一次journal日志，几兆字节的数据被写入。这意味着mongodb批量提交更改，每个写不立即刷新到磁盘